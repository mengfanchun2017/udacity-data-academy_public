{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实施 FunkSVD\n",
    "\n",
    "在此 notebook 中，我们将自己编写实施 FunkSVD 的函数，它会遵守你在上个视频中看到的步骤。如果你认为你还没有准备好自己完成这个任务，可以跳到下个视频，观看我是如何完成这些步骤的。\n",
    "\n",
    "我们将用之前使用的数据子集检测我们的算法。首先请运行以下单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-14T04:28:07.946Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import svd_tests as t\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('movies_clean.csv')\n",
    "reviews = pd.read_csv('reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']\n",
    "\n",
    "# Create user-by-item matrix\n",
    "user_items = reviews[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "user_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "\n",
    "# Create data subset\n",
    "user_movie_subset = user_by_movie[[73486, 75314,  68646, 99685]].dropna(axis=0)\n",
    "ratings_mat = np.matrix(user_movie_subset)\n",
    "print(ratings_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` 你将使用 **user_movie_subset** 矩阵演示你的 FunkSVD 算法将收敛。在以下单元格中，请参考注释和文档字符串编写你自己的 FunkSVD 函数。你也可以自己完成这些函数，不参考注释部分。你可以随意增减函数代码，使你的代码能正常运行。 \n",
    "\n",
    "**注意：**此版矩阵分解没有 ∑ 矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunkSVD(ratings_mat, latent_features=4, learning_rate=0.0001, iters=100):\n",
    "    '''\n",
    "    This function performs matrix factorization using a basic form of FunkSVD with no regularization\n",
    "    \n",
    "    INPUT:\n",
    "    ratings_mat - (numpy array) a matrix with users as rows, movies as columns, and ratings as values\n",
    "    latent_features - (int) the number of latent features used\n",
    "    learning_rate - (float) the learning rate \n",
    "    iters - (int) the number of iterations\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_mat - (numpy array) a user by latent feature matrix\n",
    "    movie_mat - (numpy array) a latent feature by movie matrix\n",
    "    '''\n",
    "    \n",
    "    # Set up useful values to be used through the rest of the function\n",
    "    n_users = # number of rows in the matrix\n",
    "    n_movies = # number of movies in the matrix\n",
    "    num_ratings = # total number of ratings in the matrix\n",
    "    \n",
    "    # initialize the user and movie matrices with random values\n",
    "    # helpful link: https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html\n",
    "    user_mat = # user matrix filled with random values of shape user x latent \n",
    "    movie_mat = # movie matrix filled with random values of shape latent x movies\n",
    "    \n",
    "    # initialize sse at 0 for first iteration\n",
    "    sse_accum = 0\n",
    "    \n",
    "    # header for running results\n",
    "    print(\"Optimization Statistics\")\n",
    "    print(\"Iterations | Mean Squared Error \")\n",
    "    \n",
    "    # for each iteration\n",
    "\n",
    "        # update our sse\n",
    "        old_sse = sse_accum\n",
    "        sse_accum = 0\n",
    "        \n",
    "        # For each user-movie pair\n",
    "                \n",
    "                # if the rating exists\n",
    "                    \n",
    "                    # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "\n",
    "                    # Keep track of the total sum of squared errors for the matrix\n",
    "                    \n",
    "                    # update the values in each matrix in the direction of the gradient\n",
    "\n",
    "        # print results for iteration\n",
    "        \n",
    "    return user_mat, movie_mat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 请在 **user_movie_subset** 数据集上尝试你的函数。先将潜在特征设为 4 个，学习速率设为 0.005，并迭代 10 次。在计算生成的 U 和 V 矩阵的点积时，生成的 **user_movie** 矩阵与原始数据子集有何区别？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mat, movie_mat = # use your function with 4 latent features, lr of 0.005 and 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the predicted and actual results\n",
    "print(np.dot(user_mat, movie_mat))\n",
    "print(ratings_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请在此处填写你的结论。**\n",
    "\n",
    "`3.` 再在 **user_movie_subset** 数据集上尝试你的函数。这次潜在特征为 4 个，学习速率设为 0.005。但是，迭代次数提高到 250 次。在计算生成的 U 和 V 矩阵的点积时，生成的 **user_movie** 矩阵与原始数据子集有何区别？迭代 250 次后，误差会怎样？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mat, movie_mat = #use your function with 4 latent features, lr of 0.005 and 250 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the predicted and actual results\n",
    "print(np.dot(user_mat, movie_mat))\n",
    "print(ratings_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请在此处填写你的结论。**\n",
    "\n",
    "上次在此矩阵里放入 **np.nan** 值时，python 中的整个 SVD 算法崩溃了。我们看看使用你的 FunkSVD 函数是否依然会这样。在以下单元格中，我在你的 numpy 数组的第一个单元格中放入了一个 NaN 值。  \n",
    "\n",
    "`4.` 假设潜在特征有 4 个，学习速率为 0.005，并且迭代 250 次。你能够运行你的 SVD 并且不崩溃吗（内置的 python 方法会崩溃）？你获得了 NaN 值的预测值吗？缺失值的预测是多少？请在以下单元格中回答这些问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are placing a nan into our original subset matrix\n",
    "ratings_mat[0, 0] = np.nan\n",
    "ratings_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run SVD on the matrix with the missing value\n",
    "user_mat, movie_mat = #use your function with 4 latent features, lr of 0.005 and 250 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see if you were able to predict for the missing value\n",
    "preds = np.dot(user_mat, movie_mat)\n",
    "print(\"The predicted value for the missing rating is {}:\".format(preds[0,0]))\n",
    "print()\n",
    "print(\"The actual value for the missing rating is {}:\".format(ratings_mat[0,0]))\n",
    "print()\n",
    "assert np.isnan(preds[0,0]) == False\n",
    "print(\"That's right! You just predicted a rating for a user-movie pair that was never rated!\")\n",
    "print(\"But if you look in the original matrix, this was actually a value of 10. Not bad!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面扩展到更真实的例子上。遗憾的是，依然不建议在本地机器上对整个用户-电影矩阵运行此函数。但是，我们能够查看这个示例扩展到 1000 个用户的情况。在上述部分，你使用了一个非常小的数据子集，并且没有缺失值。\n",
    "\n",
    "`5.` 考虑到此矩阵的大小，运行时间会比较长。假设超参数如下所示：潜在特征为 4 个，学习速率为0.005，迭代次数为20。运行时间会很久，吃点东西，散散步吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a matrix of the first 1000 users with movie ratings\n",
    "first_1000_users = np.matrix(user_by_movie.head(1000))\n",
    "\n",
    "# perform funkSVD on the matrix of the top 1000 users\n",
    "user_mat, movie_mat = #fit to 1000 users with 4 latent features, lr of 0.005, and 20 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` 现在你已经获得了每个用户-电影对的预测值，请根据你的结果回答几个问题。请在以下每个变量对应的括号里填写正确的值，并使用以下测试检测你的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace each of the comments below with the correct values\n",
    "num_ratings = # How many actual ratings exist in first_1000_users\n",
    "print(\"The number of actual ratings in the first_1000_users is {}.\".format(num_ratings))\n",
    "print()\n",
    "\n",
    "\n",
    "ratings_for_missing = # How many ratings did we make for user-movie pairs that didn't actually have ratings\n",
    "print(\"The number of ratings made for user-movie pairs that didn't have ratings is {}\".format(ratings_for_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your results against the solution\n",
    "assert num_ratings == 10852, \"Oops!  The number of actual ratings doesn't quite look right.\"\n",
    "assert ratings_for_missing == 31234148, \"Oops!  The number of movie-user pairs that you made ratings for that didn't actually have ratings doesn't look right.\"\n",
    "\n",
    "# Make sure you made predictions on all the missing user-movie pairs\n",
    "preds = np.dot(user_mat, movie_mat)\n",
    "assert np.isnan(preds).sum() == 0\n",
    "print(\"Nice job!  Looks like you have predictions made for all the missing user-movie pairs! But I still have one question... How good are they?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
